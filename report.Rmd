---
title: "Exploratory Data Analysis and Modeling: Milestone Report"
author: "Prabhat Kumar"
date: "18 March 2016"
output: 
  html_document: 
    number_sections: yes
    toc: yes
---

# Executive Summary
The goal of this project is just to display that I've gotten used to working with the [SwiftKey, Inc.](https://swiftkey.com/en/) data and that I'm on track to create the prediction algorithm. I will explain my exploratory analysis and my goals for the eventual app and algorithm.

The objective of this project is to: (1). Demonstration of how to download the data and have successfully loaded it in, (2). Create a basic report of summary statistics about the data sets, (3). Report any interesting findings that I amassed so far, and (4). Get feedback on my plans for creating a prediction algorithm and Shiny app.

# Data Acquisition
I have acquired the data from given URL, [Coursera-SwiftKey.zip](https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip). Further, unzipped the data in to ```data``` directory, by help of bash command ```unzip``` <i>i.e.</i>, is used for opening the archive; ```unzip("./data/Coursera-SwiftKey.zip")```.

```{r Environment Cleaning.}
# Remove Objects from a Specified Environment.
rm(list = ls())
```

# Reading the SwiftKey Data
I'm using here ```readLines``` method, with ```encoding = "UTF-8", skipNul = TRUE``` parameters to load/read en_US data sets, <i>i.e.</i>, en_US.blogs.txt/en_US.news.txt/en_US.twitter.txt.

```{r Reading the SwiftKey Data.}
enBlogs   <- readLines("./data/final/en_US/en_US.blogs.txt",   encoding = "UTF-8", skipNul = TRUE)
enNews    <- readLines("./data/final/en_US/en_US.news.txt",    encoding = "UTF-8", skipNul = TRUE)
enTwitter <- readLines("./data/final/en_US/en_US.twitter.txt", encoding = "UTF-8", skipNul = TRUE)
```

# Cleaning the SwiftKey Data
After, loading the data, I did cleaning of the acquired data. For this work, I've used [stringi](http://www.rexamine.com/resources/stringi/) R library.

Note: Upon examination, there is some removal of non english characters to need to be done to make the data more usable.

```{r Cleaning the SwiftKey Data.}
# working with stringi:
# http://www.rexamine.com/resources/stringi/
# Author: Marek Gagolewski, gagolews@rexamine.com/
library(stringi)

# some removal of non english characters to need to be done to make the data more usable.
# drop non UTF-8 characters.
blogs   <- iconv(enBlogs,   from = "latin1", to = "UTF-8", sub = "")
news    <- iconv(enNews,    from = "latin1", to = "UTF-8", sub = "")
twitter <- iconv(enTwitter, from = "latin1", to = "UTF-8", sub = "")

# Replace Occurrences of a Pattern.
twitter <- stri_replace_all_regex(twitter, "\u2019|`","'")
twitter <- stri_replace_all_regex(twitter, "\u201c|\u201d|u201f|``",'"')

# Save a single object to file.
saveRDS(blogs,   "./enBlogs.rds")
saveRDS(news,    "./enNews.rds")
saveRDS(twitter, "./enTwitter.rds")

# A data frame is a list of variables of the same number of rows with unique row names,
# given class "data.frame". If no variables are included,
# the row names determine the number of rows.
data.frame(blogs = length(blogs), news = length(news), twitter = length(twitter))
```

# Summary Statistics
I have performed Summary Statistics for three files only - en_US.blogs.txt, en_US.news.txt, and en_US.twitter.txt.
```{r Summary Statistics.}
# Summary Statistics for the 3 files - en_US.blogs/en_US.news/en_US.twitter
blogwords    <- sum(stri_count_words(blogs))
newswords    <- sum(stri_count_words(news))
twitterwords <- sum(stri_count_words(twitter))
# Combine Values into a Vector or List,
# This is a generic function which combines its arguments.
words        <- c(blogwords, newswords, twitterwords)

bloglines    <- length(blogs)
newslines    <- length(news)
twitterlines <- length(twitter)
# Combine Values into a Vector or List,
# This is a generic function which combines its arguments.
lines        <- c(bloglines, newslines, twitterlines)

blogmaxc     <- max(nchar(blogs))
newsmaxc     <- max(nchar(news))
twittermaxc  <- max(nchar(twitter))
# Combine Values into a Vector or List,
# This is a generic function which combines its arguments.
maxchars     <- c(blogmaxc, newsmaxc, twittermaxc)

blogmaxw     <- max(stri_count_words(blogs))
newsmaxw     <- max(stri_count_words(news))
twittermaxw  <- max(stri_count_words(twitter))
# Combine Values into a Vector or List,
# This is a generic function which combines its arguments.
maxwords     <- c(blogmaxw, newsmaxw, twittermaxw)

FileSumm     <- data.frame("File Name" = c("en_US.blogs", "en_US.news", "en_US.twitter"),
                           NumberLines = lines,
                           NumberWords = words,
                           MaxChars = maxchars,
                           MaxWords = maxwords)
```

Also, I did some basic descriptive measures of the size of the text.

```{r Basic descriptive measures.}
# Basic descriptive measures of the size of the text.
# working with knitr:
library(knitr)

basic.measures <- cbind(c("Text Chunks", "Characters"),
                  rbind(c(length(blogs),length(news),length(twitter)),
                        c(sum(nchar(blogs)),sum(nchar(news)),sum(nchar(twitter)))))
colnames(basic.measures) <- c("Measure", "Blogs", "News", "Twitter")

kable(basic.measures)
```
